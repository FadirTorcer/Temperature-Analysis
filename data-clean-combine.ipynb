{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical analysis of temperature data, QuantPy on YouTube\n",
    "# heating degree days (HDD), cooling degree days (CDD) \"average\" Temperature = Tmax + Tmin / 2\n",
    "\n",
    "# KANSAS CITY ?, 1889-01-01 to 12/31/1933\n",
    "# KANSAS CITY DOWNTOWN AIRPORT, 1/1/1934 to 9/30/1972\n",
    "# KANSAS CITY INTL AIRPORT, 10/1/1972 to 12/31/2021\n",
    "\n",
    "# Tmax, Tmin, Precipitation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kansas_city = pd.read_csv(\"data/USW00003947.csv\")\n",
    "st_louis = pd.read_csv(\"data/USW00013994.csv\")\n",
    "bhm = pd.read_csv(\"data/USW00013876.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date   tmax \n",
      "False  False    48514\n",
      "       True        63\n",
      "Name: count, dtype: int64\n",
      "Date   tmin \n",
      "False  False    48521\n",
      "       True        56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of misaligned null values equals 54\n"
     ]
    }
   ],
   "source": [
    "### Checking for missing max and min temperatures #was 63 and 56 with 54 misaligned; restricted to KCI there are 0\n",
    "max_temp = kansas_city[[\"Date\",\"tmax\"]]\n",
    "min_temp = kansas_city[[\"Date\",\"tmin\"]]\n",
    "print(max_temp.isnull().value_counts())\n",
    "print(min_temp.isnull().value_counts())\n",
    "\n",
    "count = 0\n",
    "for mx, mn in zip(np.where(max_temp.isnull())[0], np.where(min_temp.isnull())[0]):\n",
    "    if mx != mn:\n",
    "        count += 1\n",
    "print('\\nNumber of misaligned null values equals', count)\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average temps and drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kansas City\n",
      "            tmax  tmin   Tavg\n",
      "Date                         \n",
      "1889-01-01  44.0  19.0  31.50\n",
      "1889-01-02  48.0  28.0  38.00\n",
      "1889-01-03  52.0  33.0  42.50\n",
      "1889-01-04  42.0  31.0  36.50\n",
      "1889-01-05  30.0  25.0  27.50\n",
      "...          ...   ...    ...\n",
      "2021-12-27  64.0  39.0  51.50\n",
      "2021-12-28  57.0  23.2  40.10\n",
      "2021-12-29  33.1  19.2  26.15\n",
      "2021-12-30  44.1  28.2  36.15\n",
      "2021-12-31  54.0  30.9  42.45\n",
      "\n",
      "[48461 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\AppData\\Local\\Temp\\ipykernel_20940\\3690756369.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kc_temps[\"Tavg\"] = kc_temps.apply(avg_temp,axis=1)\n"
     ]
    }
   ],
   "source": [
    "kansas_city[\"Date\"] = pd.to_datetime(kansas_city[\"Date\"]) #Thanks skbrimmer!\n",
    "kansas_city.set_index(\"Date\", inplace=True)\n",
    "kc_temps = kansas_city[[\"tmax\", \"tmin\"]]\n",
    "\n",
    "def avg_temp(row):\n",
    "    return (row.tmax+row.tmin)/2\n",
    "\n",
    "kc_temps[\"Tavg\"] = kc_temps.apply(avg_temp,axis=1)\n",
    "#drop na values here\n",
    "kc_temps = kc_temps.dropna()\n",
    "print(\"Kansas City\")\n",
    "print(kc_temps)\n",
    "# print(kc_temps.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St Louis\n",
      "            tmax  tmin   Tavg\n",
      "Date                         \n",
      "1893-01-01  32.0  26.0  29.00\n",
      "1893-01-04  34.0  18.0  26.00\n",
      "1893-01-05  37.0  14.0  25.50\n",
      "1893-01-06  23.0   4.0  13.50\n",
      "1893-01-07  34.0  22.0  28.00\n",
      "...          ...   ...    ...\n",
      "2021-12-27  64.0  44.1  54.05\n",
      "2021-12-28  46.9  39.0  42.95\n",
      "2021-12-29  44.1  35.1  39.60\n",
      "2021-12-30  50.0  37.0  43.50\n",
      "2021-12-31  68.0  41.0  54.50\n",
      "\n",
      "[46989 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\AppData\\Local\\Temp\\ipykernel_20940\\1398503468.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stl_temps[\"Tavg\"] = stl_temps.apply(avg_temp,axis=1)\n"
     ]
    }
   ],
   "source": [
    "st_louis[\"Date\"] = pd.to_datetime(st_louis[\"Date\"]) #Thanks skbrimmer!\n",
    "st_louis.set_index(\"Date\", inplace=True)\n",
    "stl_temps = st_louis[[\"tmax\", \"tmin\"]]\n",
    "\n",
    "stl_temps[\"Tavg\"] = stl_temps.apply(avg_temp,axis=1)\n",
    "#drop na values here\n",
    "stl_temps = stl_temps.dropna()\n",
    "print(\"St Louis\")\n",
    "print(stl_temps)\n",
    "# print(stl_temps.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birmingham\n",
      "            tmax  tmin   Tavg\n",
      "Date                         \n",
      "1896-01-01  47.0  26.0  36.50\n",
      "1896-01-02  56.0  33.0  44.50\n",
      "1896-01-03  56.0  30.0  43.00\n",
      "1896-01-04  34.0  14.0  24.00\n",
      "1896-01-05  44.0  15.0  29.50\n",
      "...          ...   ...    ...\n",
      "2021-12-27  73.9  64.9  69.40\n",
      "2021-12-28  75.9  64.0  69.95\n",
      "2021-12-29  77.0  66.0  71.50\n",
      "2021-12-30  75.0  55.9  65.45\n",
      "2021-12-31  77.0  55.9  66.45\n",
      "\n",
      "[36385 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\AppData\\Local\\Temp\\ipykernel_20940\\2340321454.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bhm_temps[\"Tavg\"] = bhm_temps.apply(avg_temp,axis=1)\n"
     ]
    }
   ],
   "source": [
    "bhm[\"Date\"] = pd.to_datetime(bhm[\"Date\"]) #Thanks skbrimmer!\n",
    "bhm.set_index(\"Date\", inplace=True)\n",
    "bhm_temps = bhm[[\"tmax\", \"tmin\"]]\n",
    "\n",
    "bhm_temps[\"Tavg\"] = bhm_temps.apply(avg_temp,axis=1)\n",
    "#drop na values here\n",
    "bhm_temps = bhm_temps.dropna()\n",
    "print(\"Birmingham\")\n",
    "print(bhm_temps)\n",
    "# print(bhm_temps.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set start date to 1 Jan 1896 for KC and STL, join dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Programming\\Python\\Temperature-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Programming\\Python\\Temperature-Analysis\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Programming\\Python\\Temperature-Analysis\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Programming\\Python\\Temperature-Analysis\\data-clean-combine.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Programming/Python/Temperature-Analysis/data-clean-combine.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m kc_temps_1896 \u001b[39m=\u001b[39m kc_temps[kc_temps[\u001b[39m\"\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1896-01-01\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programming/Python/Temperature-Analysis/data-clean-combine.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# stl_temps_1896 = stl_temps[stl_temps[\"Date\"] > \"2009-12-31\"]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programming/Python/Temperature-Analysis/data-clean-combine.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# tricity_temps = kc_temps_1896.join([stl_temps_1896, bhm_temps])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\Python\\Temperature-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Programming\\Python\\Temperature-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "kc_temps_1896 = kc_temps[kc_temps[\"Date\"] > \"1896-01-01\"]\n",
    "# stl_temps_1896 = stl_temps[stl_temps[\"Date\"] > \"2009-12-31\"]\n",
    "# tricity_temps = kc_temps_1896.join([stl_temps_1896, bhm_temps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_temps[-5000:].plot(figsize=(8,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "kc_temps.tmin.hist(bins=60, alpha=0.6, label=\"Tmin\")\n",
    "kc_temps.tmax.hist(bins=60, alpha=0.6, label=\"Tmax\")\n",
    "kc_temps[\"Tavg\"].hist(bins=60, alpha=0.6, label=\"Tavg\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summer and Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "kc_temps_season[kc_temps_season[\"winter\"] == 1][\"Tavg\"].hist(bins=60, alpha=0.8, label=\"winter\")\n",
    "kc_temps_season[kc_temps_season[\"summer\"] == 1][\"Tavg\"].hist(bins=60, alpha=0.8, label=\"summer\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate temperature records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample by month start, calculate mins and maxes for tmax, tmin and Tavg\n",
    "date_list = kc_temps.index.tolist()\n",
    "mth_kc_temps = pd.DataFrame(data=date_list, index=date_list).resample(\"MS\")[0].agg([min,max])\n",
    "mth_kc_temps[\"month\"] = mth_kc_temps.index.month\n",
    "def min_max_temps(row):\n",
    "    stats = kc_temps[(kc_temps.index >= row[\"min\"]) & (kc_temps.index <= row[\"max\"])].agg([min, max])\n",
    "    row[\"tmax_max\"] = stats.loc[\"max\", \"tmax\"]\n",
    "    row[\"tmax_min\"] = stats.loc[\"min\", \"tmax\"]\n",
    "    row[\"tmin_max\"] = stats.loc[\"max\", \"tmin\"]\n",
    "    row[\"tmin_min\"] = stats.loc[\"min\", \"tmin\"]\n",
    "    row[\"Tavg_max\"] = stats.loc[\"max\", \"Tavg\"]\n",
    "    row[\"Tavg_min\"] = stats.loc[\"min\", \"Tavg\"]\n",
    "    return row\n",
    "\n",
    "mth_kc_temps = mth_kc_temps.apply(min_max_temps,axis=1)\n",
    "mth_kc_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremes on Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mths_kc = mth_kc_temps.groupby(mth_kc_temps.month)[[\"tmax_max\", \"tmax_min\", \"tmin_max\", \"tmin_min\", \"Tavg_max\", \"Tavg_min\"]].agg([min, max])\n",
    "grouped_mths_kc['months'] = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "grouped_mths_kc = grouped_mths_kc.set_index('months')\n",
    "print(grouped_mths_kc[[(\"tmax_max\", \"max\"),(\"tmin_min\", \"min\"),(\"tmax_min\", \"min\"),(\"tmin_max\", \"max\")]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the max and min of the Tavg max and min\n",
    "print(grouped_mths_kc[[(\"Tavg_max\", \"max\"),(\"Tavg_max\", \"min\"),(\"Tavg_min\", \"max\"),(\"Tavg_min\", \"min\")]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition of temperatures into seasonality and trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, decomposition of time-series components\n",
    "# trend - decreasin, constant or increasing?\n",
    "# seasonality - periodic signal\n",
    "# noise - variation in signal not accounted for by trend or seasonailty, a.k.a. \"remainder\"\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "kc_temps.sort_index(inplace=True)\n",
    "print(kc_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_temps[\"Tavg\"].rolling(window = 365*10).mean().plot(figsize=(8,4), color=\"tab:red\", title=\"Rolling mean over a 10 year window\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_temps[\"Tavg\"].rolling(window = 365*10).var().plot(figsize=(8,4), color=\"tab:red\", title=\"Rolling variance over a 10 year window\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal decomposition\n",
    "decompose_result = seasonal_decompose(kc_temps['Tavg'], model='additive', period=int(365*10), extrapolate_trend='freq')\n",
    " \n",
    "trend = decompose_result.trend\n",
    "seasonal = decompose_result.seasonal\n",
    "residual = decompose_result.resid\n",
    " \n",
    "decompose_result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize 10 years\n",
    "years_examine = 365*5\n",
    "start_date = 3*years_examine\n",
    "fig, axs = plt.subplots(3, figsize=(8,6))\n",
    "fig.suptitle('Removed Trend and Seasonality')\n",
    "axs[0].plot(trend[-start_date:-years_examine])\n",
    "axs[1].plot(seasonal[-start_date:-years_examine])\n",
    "axs[1].set_ylim([-25,25])\n",
    "axs[2].plot(residual[-start_date:-years_examine])\n",
    "axs[2].set_ylim([-20,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check residual distribution\n",
    "residual.hist(bins=60, figsize=(8,6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
